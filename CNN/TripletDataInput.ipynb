{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotationFilePath = '../data/33k_67k_CloudPics_groupedData_landmark_image.txt'\n",
    "with open(annotationFilePath,'r') as f:\n",
    "    annTmp = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = np.array([line.split()[0].split(\"/\")[0] for line in annTmp],dtype=np.int32)\n",
    "#fids = [[line.split()[0],[float(val)for val in line.split()[1:]]] for line in annTmp]\n",
    "fids = [line.split() for line in annTmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739936"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a tf.Dataset where one \"epoch\" loops over all PIDS.\n",
    "# PIDS are shuffled after every epoch and continue indefinitely.\n",
    "unique_pids = np.unique(pids)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(unique_pids)\n",
    "dataset = dataset.shuffle(len(unique_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_p = 2\n",
    "batch_k = 5\n",
    "# Constrain the dataset size to a multiple of the batch-size, so that\n",
    "# we don't get overlap at the end of each epoch.\n",
    "dataset = dataset.take((len(unique_pids) // batch_p) * batch_p)\n",
    "dataset = dataset.repeat(None)  # Repeat forever. Funny way of stating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_k_fids_for_pid(pid,all_pids,all_fids,batch_k):\n",
    "    \"\"\" Given a PID, select K FIDs of that specific PID. \"\"\"\n",
    "    possible_fids = tf.boolean_mask(all_fids, tf.equal(all_pids, pid))\n",
    "    #tf.Print(selected_fids,[selected_fids])\n",
    "    \n",
    "    # The following simply uses a subset of K of the possible FIDs\n",
    "    # if more than, or exactly K are available. Otherwise, we first\n",
    "    # create a padded list of indices which contain a multiple of the\n",
    "    # original FID count such that all of them will be sampled equally likely.\n",
    "    count = tf.shape(possible_fids)[0]\n",
    "    padded_count = tf.cast(tf.ceil(tf.cast(batch_k,tf.float32) / tf.cast(count,tf.float32)), tf.int32) * count\n",
    "    full_range = tf.mod(tf.range(padded_count), count)\n",
    "\n",
    "    # Sampling is always performed by shuffling and taking the first k.\n",
    "    shuffled = tf.random_shuffle(full_range)\n",
    "    selected_fids = tf.gather(possible_fids, shuffled[:batch_k])\n",
    "    selected_landmark = tf.string_to_number(selected_fids[:,1:],tf.float32)\n",
    "    selected_fids = selected_fids[:,0]\n",
    "    return selected_fids, selected_landmark, tf.fill([batch_k], pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every PID, get K images.\n",
    "dataset = dataset.map(lambda pid: sample_k_fids_for_pid(pid, all_pids=pids,\n",
    "                                                        all_fids=fids,\n",
    "                                                        batch_k=batch_k),4)\n",
    "# Ungroup/flatten the batches for easy loading of the files.\n",
    "dataset = dataset.apply(tf.contrib.data.unbatch())\n",
    "\n",
    "# Group it back into PK batches.\n",
    "batch_size = batch_p * batch_k\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "# Overlap producing and consuming for parallelism.\n",
    "dataset = dataset.prefetch(5)\n",
    "\n",
    "# Since we repeat the data infinitely, we only need a one-shot iterator.\n",
    "#images, fids, pids = dataset.make_one_shot_iterator().get_next()\n",
    "imgPath,landmark,labels = dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) [ 2307  2307  2307  2307  2307 20174 20174 20174 20174 20174]\n",
      "(10,) [ 62383  62383  62383  62383  62383 123978 123978 123978 123978 123978]\n",
      "(10,) [123042 123042 123042 123042 123042    192    192    192    192    192]\n",
      "(10,) [74744 74744 74744 74744 74744 93452 93452 93452 93452 93452]\n",
      "(10,) [ 41130  41130  41130  41130  41130 116159 116159 116159 116159 116159]\n",
      "(10,) [83348 83348 83348 83348 83348  6231  6231  6231  6231  6231]\n",
      "(10,) [83181 83181 83181 83181 83181 10920 10920 10920 10920 10920]\n",
      "(10,) [137419 137419 137419 137419 137419 128298 128298 128298 128298 128298]\n",
      "(10,) [41780 41780 41780 41780 41780 63668 63668 63668 63668 63668]\n",
      "(10,) [143043 143043 143043 143043 143043  86165  86165  86165  86165  86165]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    for i in xrange(10):\n",
    "        imgPath_val,landmark_val,labels_val = sess.run([imgPath,landmark,labels])\n",
    "        print labels_val.shape, labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print imgPath_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 54574  54574  54574  54574  54574]\n",
      " [ 44771  44771  44771  44771  44771]\n",
      " [  5464   5464   5464   5464   5464]\n",
      " [ 92208  92208  92208  92208  92208]\n",
      " [  9353   9353   9353   9353   9353]\n",
      " [  7830   7830   7830   7830   7830]\n",
      " [107139 107139 107139 107139 107139]\n",
      " [ 32676  32676  32676  32676  32676]\n",
      " [  9163   9163   9163   9163   9163]\n",
      " [112511 112511 112511 112511 112511]]\n",
      "[[119658 119658 119658 119658 119658]\n",
      " [143018 143018 143018 143018 143018]\n",
      " [ 67021  67021  67021  67021  67021]\n",
      " [139286 139286 139286 139286 139286]\n",
      " [114781 114781 114781 114781 114781]\n",
      " [ 70869  70869  70869  70869  70869]\n",
      " [ 10340  10340  10340  10340  10340]\n",
      " [ 65278  65278  65278  65278  65278]\n",
      " [132451 132451 132451 132451 132451]\n",
      " [142777 142777 142777 142777 142777]]\n",
      "[[ 54525  54525  54525  54525  54525]\n",
      " [138225 138225 138225 138225 138225]\n",
      " [  2180   2180   2180   2180   2180]\n",
      " [ 24917  24917  24917  24917  24917]\n",
      " [111470 111470 111470 111470 111470]\n",
      " [ 45116  45116  45116  45116  45116]\n",
      " [142804 142804 142804 142804 142804]\n",
      " [ 60633  60633  60633  60633  60633]\n",
      " [119074 119074 119074 119074 119074]\n",
      " [113304 113304 113304 113304 113304]]\n",
      "[[ 41107  41107  41107  41107  41107]\n",
      " [  6022   6022   6022   6022   6022]\n",
      " [125404 125404 125404 125404 125404]\n",
      " [133762 133762 133762 133762 133762]\n",
      " [ 27030  27030  27030  27030  27030]\n",
      " [ 33658  33658  33658  33658  33658]\n",
      " [143319 143319 143319 143319 143319]\n",
      " [110894 110894 110894 110894 110894]\n",
      " [ 18349  18349  18349  18349  18349]\n",
      " [146455 146455 146455 146455 146455]]\n",
      "[[ 26873  26873  26873  26873  26873]\n",
      " [  5821   5821   5821   5821   5821]\n",
      " [ 60820  60820  60820  60820  60820]\n",
      " [ 46551  46551  46551  46551  46551]\n",
      " [ 16405  16405  16405  16405  16405]\n",
      " [ 73612  73612  73612  73612  73612]\n",
      " [129484 129484 129484 129484 129484]\n",
      " [105117 105117 105117 105117 105117]\n",
      " [136376 136376 136376 136376 136376]\n",
      " [  6987   6987   6987   6987   6987]]\n",
      "[[ 18085  18085  18085  18085  18085]\n",
      " [ 10294  10294  10294  10294  10294]\n",
      " [  9139   9139   9139   9139   9139]\n",
      " [105815 105815 105815 105815 105815]\n",
      " [ 73986  73986  73986  73986  73986]\n",
      " [ 45492  45492  45492  45492  45492]\n",
      " [100972 100972 100972 100972 100972]\n",
      " [ 12834  12834  12834  12834  12834]\n",
      " [ 31760  31760  31760  31760  31760]\n",
      " [ 10825  10825  10825  10825  10825]]\n",
      "[[ 19327  19327  19327  19327  19327]\n",
      " [ 19019  19019  19019  19019  19019]\n",
      " [  4652   4652   4652   4652   4652]\n",
      " [ 76946  76946  76946  76946  76946]\n",
      " [107337 107337 107337 107337 107337]\n",
      " [ 24489  24489  24489  24489  24489]\n",
      " [ 46982  46982  46982  46982  46982]\n",
      " [ 51793  51793  51793  51793  51793]\n",
      " [ 76540  76540  76540  76540  76540]\n",
      " [144622 144622 144622 144622 144622]]\n",
      "[[ 41774  41774  41774  41774  41774]\n",
      " [ 37476  37476  37476  37476  37476]\n",
      " [ 97328  97328  97328  97328  97328]\n",
      " [  2041   2041   2041   2041   2041]\n",
      " [133630 133630 133630 133630 133630]\n",
      " [ 67180  67180  67180  67180  67180]\n",
      " [ 70862  70862  70862  70862  70862]\n",
      " [  2888   2888   2888   2888   2888]\n",
      " [ 93815  93815  93815  93815  93815]\n",
      " [ 49025  49025  49025  49025  49025]]\n",
      "[[ 15790  15790  15790  15790  15790]\n",
      " [ 89218  89218  89218  89218  89218]\n",
      " [ 69153  69153  69153  69153  69153]\n",
      " [140233 140233 140233 140233 140233]\n",
      " [110025 110025 110025 110025 110025]\n",
      " [ 41274  41274  41274  41274  41274]\n",
      " [ 66190  66190  66190  66190  66190]\n",
      " [132043 132043 132043 132043 132043]\n",
      " [120300 120300 120300 120300 120300]\n",
      " [119332 119332 119332 119332 119332]]\n",
      "[[140717 140717 140717 140717 140717]\n",
      " [ 67825  67825  67825  67825  67825]\n",
      " [ 72055  72055  72055  72055  72055]\n",
      " [115209 115209 115209 115209 115209]\n",
      " [111722 111722 111722 111722 111722]\n",
      " [ 26412  26412  26412  26412  26412]\n",
      " [ 18224  18224  18224  18224  18224]\n",
      " [114483 114483 114483 114483 114483]\n",
      " [  8495   8495   8495   8495   8495]\n",
      " [ 76792  76792  76792  76792  76792]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    for i in xrange(10):\n",
    "        imgPath_val,landmark_val,labels_val = sess.run([imgPath,landmark,labels])\n",
    "        print labels_val.shape, labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 283.  302.  433.  300.  360.  405.  314.  470.  415.  469.]\n",
      "  [ 291.  299.  440.  302.  366.  404.  313.  468.  411.  471.]\n",
      "  [ 283.  302.  433.  300.  360.  405.  314.  470.  415.  469.]\n",
      "  [ 283.  302.  433.  300.  360.  405.  314.  470.  415.  469.]\n",
      "  [ 133.  144.  203.  144.  169.  187.  147.  218.  193.  217.]\n",
      "  [ 137.  143.  208.  144.  171.  186.  147.  216.  192.  216.]\n",
      "  [ 137.  143.  208.  144.  171.  186.  147.  216.  192.  216.]\n",
      "  [ 291.  299.  440.  302.  366.  404.  313.  468.  411.  471.]\n",
      "  [ 137.  143.  208.  144.  171.  186.  147.  216.  192.  216.]\n",
      "  [ 133.  144.  203.  144.  169.  187.  147.  218.  193.  217.]]]\n"
     ]
    }
   ],
   "source": [
    "print fid_batch_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
